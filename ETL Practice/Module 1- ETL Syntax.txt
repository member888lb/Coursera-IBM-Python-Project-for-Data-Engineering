Python Project for Data Engineering
ETL Syntax

source1.json
source2.json
source3.json
source1.csv
source2.csv
source3.csv
 

Syntax
import glob

list_csv=glob.glob('*.csv')

list_csv:['source1.csv','source2.csv', 'source3.csv']


Syntax
list_json=glob.glob('*.json')

List_json:['source1.json','source2.json','source3.json']
 

Syntax
def extract_from_csv(file_to_process):
dataframe = pd.read_csv(file_to_process)
returndataframe

df=extract_from_csv('source1.csv')


Syntax
def extract_from_json(file_to_process):
dataframe = pd.read_json(file_to_process,lines=True)
return dataframe

df=extract_from_jason('source1.json')


Syntax
def extract():

# create an empty data frame to hold extracted data

extracted_data = pd.DataFrame(columns=['name','height','weight'])

# process all csv files

for csvfile in glob.glob("*.csv"):
extracted_data = extracted_data.append(extract_from_csv(csvfile),
ignore_index=True)

# process all json files

for jsonfile in glob.glob("*.json"):
extracted_data = extracted_data.append(extract_from_json(jsonfile),
ignore_index=True) 

return extracted_data


Syntax
extracted_data = pd.DataFrame(columns=['name','height','weight'])


Syntax
for csvfile in glob.glob("*.csv"):
extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)


Syntax
def tranform(data):
# Convert height which is in inches to millimeter

# Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)

data['height'] = round(data.height * 0.0254,2)

# Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 killograms)

data['weight'] = round(data.weight * 0.45359237,2)

return data
 

Syntax
def load(targetfile,data_to_load):
data_to_load.to_csv(targetfile)

targetfile = "transformed_data.csv"

load(targetfile,transformed_data)


Syntax
from datetime import datetime

def log(message):
timestamp_format = '%Y-%h-%d-%H:%M:%S'
now = datetime.now()
timestamp = now.strftime(timestamp_format)
with open( "logfile.txt" , "a" ) as f:
f.write ( timestamp + ',' + message + '\n' )


Syntax
log( "ETL Job Started" )

log( "Extract phase Started" )
extracted_data = extract()
log( "Extracted phase Ended" )

log( "Transform Job Started" )
transformed_data = transform( extracted_data )
log( "Transform Job Ended" )

log( "Load Job Started" )
load( targetfile, transformed_data )
log( "Load Job Ended" )

log( "ETL Job Ended" )


HANDS-ON LAB: ETL

Skills Network Labs - https://www.coursera.org/learn/python-project-for-data-engineering/ungradedLti/oWmyy/hands-on-lab-extract-transform-load-etl

Objectives
1. Read CSV, JSON, and XML file types.
2. Extract the required data from the different file types.
3. Transform data to the required format.
4. Save the transformed data in a ready-to-load format, which can be loaded into an RDBMS.

STEP 1 - Create File

Create file called:  etl_code.py

STEP 2 - Get Data from URL and Unzip It

Syntax
$ wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip

Data is in a zip file; unzip it.

Syntax:
unzip source.zip

STEP 3 - Instruction Summary 

Importing Libraries and setting paths
1. The xml library can be used to parse the information from an .xml file format. 
2. The .csv and .json file formats can be read using the pandas library. 
3. You will use the pandas library to create a data frame format that will store the extracted data from any file.
4. To call the correct function for data extraction, you need to access the file format information. For this access, you can use the glob library.
5. To log the information correctly, you need the date and time information at the point of logging. For this information, you require the datetime package.
6. While glob, xml, and datetime are inbuilt features of Python, you need to install the pandas library to your IDE.

STEP 4 - Update Python package

Syntax:
python3.11 -m pip install pandas

STEP 5 - Install Libraries

After the installation is complete, you can import all the libraries in etl_code.py using the following commands.

import glob 
import pandas as pd 
import xml.etree.ElementTree as ET 
from datetime import datetime 

STEP 6 - Install ElementTree Function (for XML format)

Note that you import only the ElementTree function from the xml.etree library because you require that function to parse the data from an XML file format.

You also require two file paths that will be available globally in the code for all functions. These are transformed_data.csv, to store the final output data that you can load to a database, and log_file.txt, that stores all the logs.

Introduce these paths in the etl_code by adding the following statements:

log_file = "log_file.txt" 
target_file = "transformed_data.csv" 

STEP 7 - Extraction

There are different functions for the file formats, you need to write one function each for the .csv, .json, and .xml filetypes.

You can name these 3 functions as:
extract_from_csv()
extract_from_json()
extract_from_xml() 

You need to pass the data file as an argument, file_to_process, to each.  The argument is ().

To extract from a CSV file, you can define the function extract_from_csv()as follows using the pandas function read_csv:

etl_code
def extract_from_csv(file_to_process): 
dataframe = pd.read_csv(file_to_process) 
return dataframe 


To extract from a JSON file, you can define the function extract_from_json()using the pandas function read_json. It requires an extra argument lines=True to enable the function to read the file as a JSON object on line to line basis as follows.

etl_code
def extract_from_json(file_to_process): 
    dataframe = pd.read_json(file_to_process, lines=True) 
    return dataframe 


To extract from an XML file, you need first to parse the data from the file using the ElementTree function. You can then extract relevant information from this data and append it to a pandas dataframe as follows.  Note: You must know the headers of the extracted data to write this function. In this data, you extract "name", "height", and "weight" headers for different persons.

etl_code
def extract_from_xml(file_to_process): 
    dataframe = pd.DataFrame(columns=["name", "height", "weight"]) 
    tree = ET.parse(file_to_process) 
    root = tree.getroot() 
    for person in root: 
        name = person.find("name").text 
        height = float(person.find("height").text) 
        weight = float(person.find("weight").text) 
        dataframe = pd.concat([dataframe, pd.DataFrame([{"name":name, "height":height, "weight":weight}])], ignore_index=True) 
    return dataframe 


STEP 8 - glob
Now you need a function to identify which function to call on basis of the filetype of the data file. To call the relevant function, write a function extract, which uses the glob library to identify the filetype. This can be done as follows:

etl_code
def extract(): 
    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data 
     
    # process all csv files 
    for csvfile in glob.glob("*.csv"): 
        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) 
         
    # process all json files 
    for jsonfile in glob.glob("*.json"): 
        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) 
     
    # process all xml files 
    for xmlfile in glob.glob("*.xml"): 
        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) 
         
    return extracted_data 

After adding these functions to etl_code.py you complete the implementation of the extraction part.

STEP 9 - Tranformation

The height in data is inches, and weight in pounds. For your application, height must be in meters, and weight in kilograms, rounded to two decimal places. You need to write the function to perform the unit conversion for the two parameters.

The name of this function will be transform(), and it will receive the extracted dataframe as the input. Since the dataframe is in the form of a dictionary with three keys, "name", "height", and "weight", each of them having a list of values, you can apply the transform function on the entire list at one go.

etl_code
def transform(data): 
    # Convert inches to meters and round off to two decimals 
    1 inch is 0.0254 meters
    data['height'] = round(data.height * 0.0254,2) 
 
    # Convert pounds to kilograms and round off to two decimals 
    1 pound is 0.45359237 kilograms
    data['weight'] = round(data.weight * 0.45359237,2) 
    
    return data 


STEP 10 - Loading and Logging

To load the CSV data, you need a function load_data() that accepts the transformed data as a dataframe and the target_file path. You need to use the to_csv attribute of the dataframe in the function as follows:

etl_code
def load_data(target_file, transformed_data): 
    transformed_data.to_csv(target_file) 

You need to implement the logging operation to record the progress of the different operations. For this operation, you need to record a message, along with its timestamp, in the log_file.

To record the message, you need to implement a function log_progress() that accepts the log message as the argument. The function captures the current date and time using the datetime function from the datetime library. The use of this function requires the definition of a date-time format, and you need to convert the timestamp to a string format using the strftime attribute. The following code creates the log operation:

etl_code
def log_progress(message): 
    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second 
    now = datetime.now() # get current timestamp 
    timestamp = now.strftime(timestamp_format) 
    with open(log_file,"a") as f: 
        f.write(timestamp + ',' + message + '\n') 


With this, all the functions for Extract, Transform, and Load (ETL) are ready for testing

STEP 11 - Testing ETL operations and log progress

etl_code
# Log the initialization of the ETL process 
log_progress("ETL Job Started") 
 
# Log the beginning of the Extraction process 
log_progress("Extract phase Started") 
extracted_data = extract() 
 
# Log the completion of the Extraction process 
log_progress("Extract phase Ended") 
 
# Log the beginning of the Transformation process 
log_progress("Transform phase Started") 
transformed_data = transform(extracted_data) 
print("Transformed Data") 
print(transformed_data) 
 
# Log the completion of the Transformation process 
log_progress("Transform phase Ended") 
 
# Log the beginning of the Loading process 
log_progress("Load phase Started") 
load_data(target_file,transformed_data) 
 
# Log the completion of the Loading process 
log_progress("Load phase Ended") 
 
# Log the completion of the ETL process 
log_progress("ETL Job Ended") 

STEP 12 - Execution of code

Syntax:
python3.11 etl_code.py 










